server:
  port: 8081

logging:
  level:
    com.mwc: DEBUG
    org.springframework.sql: DEBUG
#    org.apache.kafka: DEBUG
#    org.springframework.kafka: DEBUG

spring:
  # Always include the "secrets" profile so we also load `application-secrets.yml`
  profiles:
    include: secrets
  jpa:
    open-in-view: false
    show-sql: true
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect

  datasource:
    username: order_user
    password: order_password
    url: jdbc:postgresql://localhost:5435/postgres?currentSchema=inventory,warehouse&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
#    url: jdbc:postgresql://34.50.77.24:5432/inventorydb?currentSchema=public&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
    driver-class-name: org.postgresql.Driver
    schema-locations: classpath:warehouse-schema.sql, classpath:init-schema.sql, classpath:inventory-data.sql, classpath:inventory-item-data.sql, classpath:warehouse-data.sql

  data:
    mongodb:
      uri: mongodb://localhost:27017/order_view
      database: inventory_read_db
#      auto-index-creation: true

  sql:
    init:
      platform: postgres
      mode: never
      schema-locations: classpath:init-schema.sql, classpath:inventory-data.sql,classpath:inventory-item-data.sql,classpath:warehouse-schema.sql,classpath:warehouse-data.sql

# Example application-level config
inventory-service:
  stock-decrement-request-topic-name: stock-decrement-request
  stock-decrement-response-topic-name: stock-decrement-response
  stock-increment-topic-name: stock-increment-request
  stock-increment-response-topic-name: stock-increment-response

# ----------------------------------------------------------------
# KAFKA CONFIG FOR CONFLUENT CLOUD (common or default)
# ----------------------------------------------------------------
kafka-config:
  # schema-registry-user-info-key: basic.auth.credentials.source
  # schema-registry-user-info: USER_INFO
  # schema-registry-basic-auth-user-info-key: schema.registry.basic.auth.user.info
  # schema-registry-basic-auth-user-info: "SR_KEY:SR_SECRET"
  # sasl-jaas-config: >
  #   org.apache.kafka.common.security.plain.PlainLoginModule required
  #   username
  # bootstrap-servers: pkc-ew3qg.asia-southeast2.gcp.confluent.cloud:9092
  # schema-registry-url-key: schema.registry.url
  # schema-registry-url: https://psrc-epk8y.australia-southeast1.gcp.confluent.cloud
  # num-of-partitions: 3
  # replication-factor: 3
  # security-protocol: SASL_SSL
  # sasl-mechanism: PLAIN
  bootstrap-servers: 34.101.89.132:32100
  schema-registry-url-key: schema.registry.url
  schema-registry-url: https://schema-registry.fadellh.com
  num-of-partitions: 3
  replication-factor: 3
  security-protocol: PLAINTEXT
  sasl-mechanism: PLAIN

# Producer configs
kafka-producer-config:
  key-serializer-class: org.apache.kafka.common.serialization.StringSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  compression-type: snappy
  acks: all
  batch-size: 16384
  batch-size-boost-factor: 100
  linger-ms: 5
  request-timeout-ms: 60000
  retry-count: 5

# Consumer configs (if needed for Avro consumer)
kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  stock-decrement-consumer-group-id: stock-decrement-topic-consumer
  auto-offset-reset: earliest
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  batch-listener: true
  auto-startup: true
  concurrency-level: 3
  session-timeout-ms: 10000
  heartbeat-interval-ms: 3000
  max-poll-interval-ms: 300000
  max-poll-records: 500
  max-partition-fetch-bytes-default: 1048576
  max-partition-fetch-bytes-boost-factor: 1
  poll-timeout-ms: 150
