apiVersion: v1
kind: ConfigMap
metadata:
  name: inventory-service-config
  namespace: default
data:
  application.yml: |
    server:
      port: 8081

    logging:
      level:
        com.mwc: DEBUG
        org.springframework.sql: DEBUG
    #    org.apache.kafka: DEBUG
    #    org.springframework.kafka: DEBUG

    spring:
      # Always include the "secrets" profile so we also load `application-secrets.yml`
      profiles:
        include: secrets
      jpa:
        open-in-view: false
        show-sql: true
        database-platform: org.hibernate.dialect.PostgreSQLDialect
        properties:
          hibernate:
            dialect: org.hibernate.dialect.PostgreSQLDialect

      datasource:
        url: jdbc:postgresql://localhost:5435/postgres?currentSchema=inventory,warehouse&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
        driver-class-name: org.postgresql.Driver
        schema-locations: classpath:warehouse-schema.sql, classpath:init-schema.sql, classpath:inventory-data.sql, classpath:inventory-item-data.sql, classpath:warehouse-data.sql

      data:
        mongodb:
          database: inventory_view
          auto-index-creation: true

      sql:
        init:
          platform: postgres
          mode: always
          schema-locations: classpath:init-schema.sql, classpath:inventory-data.sql,classpath:inventory-item-data.sql,classpath:warehouse-schema.sql,classpath:warehouse-data.sql

    # Example application-level config
    inventory-service:
      stock-decrement-request-topic-name: stock-decrement-request
      stock-decrement-response-topic-name: stock-decrement-response
      stock-increment-topic-name: stock-increment-request
      stock-increment-response-topic-name: stock-increment-response

    # ----------------------------------------------------------------
    # KAFKA CONFIG FOR CONFLUENT CLOUD (common or default)
    # ----------------------------------------------------------------
    kafka-config:
      bootstrap-servers: pkc-ew3qg.asia-southeast2.gcp.confluent.cloud:9092
      schema-registry-url-key: schema.registry.url
      schema-registry-url: https://psrc-epk8y.australia-southeast1.gcp.confluent.cloud
      num-of-partitions: 3
      replication-factor: 3
      security-protocol: SASL_SSL
      sasl-mechanism: PLAIN

    # Producer configs
    kafka-producer-config:
      key-serializer-class: org.apache.kafka.common.serialization.StringSerializer
      value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
      compression-type: snappy
      acks: all
      batch-size: 16384
      batch-size-boost-factor: 100
      linger-ms: 5
      request-timeout-ms: 60000
      retry-count: 5

    # Consumer configs (if needed for Avro consumer)
    kafka-consumer-config:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      stock-decrement-consumer-group-id: stock-decrement-topic-consumer
      auto-offset-reset: earliest
      specific-avro-reader-key: specific.avro.reader
      specific-avro-reader: true
      batch-listener: true
      auto-startup: true
      concurrency-level: 3
      session-timeout-ms: 10000
      heartbeat-interval-ms: 3000
      max-poll-interval-ms: 300000
      max-poll-records: 500
      max-partition-fetch-bytes-default: 1048576
      max-partition-fetch-bytes-boost-factor: 1
      poll-timeout-ms: 150
